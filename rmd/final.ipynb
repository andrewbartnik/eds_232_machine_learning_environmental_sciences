{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test1=pd.read_csv(\"/Users/andrewbartnik/Desktop/MEDS/Winter/Machine Learning/Labs/ML/test.csv\")\n",
    "test = test1.drop(columns=test1.columns[0]).rename(columns={'TA1': 'TA1.x'})\n",
    "\n",
    "train=pd.read_csv(\"/Users/andrewbartnik/Desktop/MEDS/Winter/Machine Learning/Labs/ML/train.csv\")\n",
    "train = train.drop(columns=[train.columns[0], train.columns[12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                    Type         Data/Info\n",
      "--------------------------------------------------\n",
      "GradientBoostingRegressor   ABCMeta      <class 'sklearn.ensemble.<...>adientBoostingRegressor'>\n",
      "GridSearchCV                ABCMeta      <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
      "Pipeline                    ABCMeta      <class 'sklearn.pipeline.Pipeline'>\n",
      "StandardScaler              type         <class 'sklearn.preproces<...>ng._data.StandardScaler'>\n",
      "StratifiedKFold             ABCMeta      <class 'sklearn.model_sel<...>._split.StratifiedKFold'>\n",
      "XGBRegressor                type         <class 'xgboost.sklearn.XGBRegressor'>\n",
      "mean_squared_error          function     <function mean_squared_error at 0x7f9265614940>\n",
      "np                          module       <module 'numpy' from '/Us<...>kages/numpy/__init__.py'>\n",
      "os                          module       <module 'os' from '/Users<...>env/lib/python3.8/os.py'>\n",
      "pd                          module       <module 'pandas' from '/U<...>ages/pandas/__init__.py'>\n",
      "sys                         module       <module 'sys' (built-in)>\n",
      "test                        DataFrame           Lat_Dec     Lon_De<...>\\n[485 rows x 16 columns]\n",
      "test1                       DataFrame           id    Lat_Dec     <...>\\n[485 rows x 17 columns]\n",
      "train                       DataFrame            Lat_Dec     Lon_D<...>n[1454 rows x 17 columns]\n",
      "train_test_split            function     <function train_test_split at 0x7f926551baf0>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Lat_Dec     Lon_Dec  NO2uM  NO3uM  NH3uM  R_TEMP  R_Depth  R_Sal  \\\n",
      "0  34.321666 -120.811666   0.02   24.0   0.41    9.51      101  189.9   \n",
      "1  34.275000 -120.033333   0.00   25.1   0.00    9.84      102  185.2   \n",
      "2  34.275000 -120.033333   0.00   31.9   0.00    6.60      514  124.1   \n",
      "3  33.828333 -118.625000   0.00    0.0   0.20   19.21        1  408.1   \n",
      "4  33.828333 -118.625000   0.02   19.7   0.00   10.65      100  215.5   \n",
      "\n",
      "   R_DYNHT  R_Nuts  R_Oxy_micromol.Kg  PO4uM  SiO3uM    TA1.x  Salinity1  \\\n",
      "0    0.258    0.41         138.838300   1.85    25.5  2244.94     33.830   \n",
      "1    0.264    0.00         102.709200   2.06    28.3  2253.27     33.963   \n",
      "2    0.874    0.00           2.174548   3.40    88.1  2316.95     34.241   \n",
      "3    0.004    0.20         258.674300   0.27     2.5  2240.49     33.465   \n",
      "4    0.274    0.00         145.839900   1.64    19.4  2238.30     33.720   \n",
      "\n",
      "   Temperature_degC  \n",
      "0              9.52  \n",
      "1              9.85  \n",
      "2              6.65  \n",
      "3             19.21  \n",
      "4             10.66  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat_Dec</th>\n",
       "      <th>Lon_Dec</th>\n",
       "      <th>NO2uM</th>\n",
       "      <th>NO3uM</th>\n",
       "      <th>NH3uM</th>\n",
       "      <th>R_TEMP</th>\n",
       "      <th>R_Depth</th>\n",
       "      <th>R_Sal</th>\n",
       "      <th>R_DYNHT</th>\n",
       "      <th>R_Nuts</th>\n",
       "      <th>R_Oxy_micromol.Kg</th>\n",
       "      <th>PO4uM</th>\n",
       "      <th>SiO3uM</th>\n",
       "      <th>TA1.x</th>\n",
       "      <th>Salinity1</th>\n",
       "      <th>Temperature_degC</th>\n",
       "      <th>DIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.385030</td>\n",
       "      <td>-120.665530</td>\n",
       "      <td>0.030</td>\n",
       "      <td>33.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.79</td>\n",
       "      <td>323</td>\n",
       "      <td>141.2</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.40948</td>\n",
       "      <td>2.77</td>\n",
       "      <td>53.86</td>\n",
       "      <td>2287.45</td>\n",
       "      <td>34.198</td>\n",
       "      <td>7.82</td>\n",
       "      <td>2270.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.418333</td>\n",
       "      <td>-121.998333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.12</td>\n",
       "      <td>323</td>\n",
       "      <td>140.8</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.81441</td>\n",
       "      <td>2.57</td>\n",
       "      <td>52.50</td>\n",
       "      <td>2279.10</td>\n",
       "      <td>34.074</td>\n",
       "      <td>7.15</td>\n",
       "      <td>2254.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.385030</td>\n",
       "      <td>-120.665530</td>\n",
       "      <td>0.180</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.68</td>\n",
       "      <td>50</td>\n",
       "      <td>246.8</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.29150</td>\n",
       "      <td>1.29</td>\n",
       "      <td>13.01</td>\n",
       "      <td>2230.80</td>\n",
       "      <td>33.537</td>\n",
       "      <td>11.68</td>\n",
       "      <td>2111.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.482580</td>\n",
       "      <td>-122.533070</td>\n",
       "      <td>0.013</td>\n",
       "      <td>29.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.33</td>\n",
       "      <td>232</td>\n",
       "      <td>158.5</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.01</td>\n",
       "      <td>89.62595</td>\n",
       "      <td>2.27</td>\n",
       "      <td>38.98</td>\n",
       "      <td>2265.85</td>\n",
       "      <td>34.048</td>\n",
       "      <td>8.36</td>\n",
       "      <td>2223.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.414320</td>\n",
       "      <td>-121.997670</td>\n",
       "      <td>0.000</td>\n",
       "      <td>33.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.53</td>\n",
       "      <td>323</td>\n",
       "      <td>143.4</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.05</td>\n",
       "      <td>60.03062</td>\n",
       "      <td>2.53</td>\n",
       "      <td>49.28</td>\n",
       "      <td>2278.49</td>\n",
       "      <td>34.117</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2252.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lat_Dec     Lon_Dec  NO2uM  NO3uM  NH3uM  R_TEMP  R_Depth  R_Sal  \\\n",
       "0  34.385030 -120.665530  0.030  33.80   0.00    7.79      323  141.2   \n",
       "1  31.418333 -121.998333  0.000  34.70   0.00    7.12      323  140.8   \n",
       "2  34.385030 -120.665530  0.180  14.20   0.00   11.68       50  246.8   \n",
       "3  33.482580 -122.533070  0.013  29.67   0.01    8.33      232  158.5   \n",
       "4  31.414320 -121.997670  0.000  33.10   0.05    7.53      323  143.4   \n",
       "\n",
       "   R_DYNHT  R_Nuts  R_Oxy_micromol.Kg  PO4uM  SiO3uM    TA1.x  Salinity1  \\\n",
       "0    0.642    0.00           37.40948   2.77   53.86  2287.45     34.198   \n",
       "1    0.767    0.00           64.81441   2.57   52.50  2279.10     34.074   \n",
       "2    0.144    0.00          180.29150   1.29   13.01  2230.80     33.537   \n",
       "3    0.562    0.01           89.62595   2.27   38.98  2265.85     34.048   \n",
       "4    0.740    0.05           60.03062   2.53   49.28  2278.49     34.117   \n",
       "\n",
       "   Temperature_degC      DIC  \n",
       "0              7.82  2270.17  \n",
       "1              7.15  2254.10  \n",
       "2             11.68  2111.04  \n",
       "3              8.36  2223.41  \n",
       "4              7.57  2252.62  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.head())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = train.drop(columns=['DIC'])\n",
    "y_train = train['DIC']\n",
    "\n",
    "# Split the train DataFrame into a training set and a holdout set (80% train, 20% holdout)\n",
    "X_train_cv, X_holdout, y_train_cv, y_holdout = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                    Type         Data/Info\n",
      "--------------------------------------------------\n",
      "GradientBoostingRegressor   ABCMeta      <class 'sklearn.ensemble.<...>adientBoostingRegressor'>\n",
      "GridSearchCV                ABCMeta      <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
      "Pipeline                    ABCMeta      <class 'sklearn.pipeline.Pipeline'>\n",
      "StandardScaler              type         <class 'sklearn.preproces<...>ng._data.StandardScaler'>\n",
      "StratifiedKFold             ABCMeta      <class 'sklearn.model_sel<...>._split.StratifiedKFold'>\n",
      "XGBRegressor                type         <class 'xgboost.sklearn.XGBRegressor'>\n",
      "X_holdout                   DataFrame            Lat_Dec     Lon_D<...>\\n[291 rows x 16 columns]\n",
      "X_train                     DataFrame            Lat_Dec     Lon_D<...>n[1454 rows x 16 columns]\n",
      "X_train_cv                  DataFrame            Lat_Dec     Lon_D<...>n[1163 rows x 16 columns]\n",
      "mean_squared_error          function     <function mean_squared_error at 0x7f9265614940>\n",
      "np                          module       <module 'numpy' from '/Us<...>kages/numpy/__init__.py'>\n",
      "os                          module       <module 'os' from '/Users<...>env/lib/python3.8/os.py'>\n",
      "pd                          module       <module 'pandas' from '/U<...>ages/pandas/__init__.py'>\n",
      "sys                         module       <module 'sys' (built-in)>\n",
      "test                        DataFrame           Lat_Dec     Lon_De<...>\\n[485 rows x 16 columns]\n",
      "test1                       DataFrame           id    Lat_Dec     <...>\\n[485 rows x 17 columns]\n",
      "train                       DataFrame            Lat_Dec     Lon_D<...>n[1454 rows x 17 columns]\n",
      "train_test_split            function     <function train_test_split at 0x7f926551baf0>\n",
      "y_holdout                   Series       497     2015.590000\\n1260<...>ngth: 291, dtype: float64\n",
      "y_train                     Series       0       2270.17\\n1       <...>gth: 1454, dtype: float64\n",
      "y_train_cv                  Series       720     2311.33\\n254     <...>gth: 1163, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Create a pipeline with StandardScaler and the initialized XGBRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', xgb)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m learning_rates \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.01\u001b[39m, \u001b[39m0.35\u001b[39m, \u001b[39m70\u001b[39m)\n\u001b[1;32m      3\u001b[0m param_grid_learning_rate \u001b[39m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mxgb__learning_rate\u001b[39m\u001b[39m'\u001b[39m: learning_rates\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m grid_search_lr \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[0;32m----> 8\u001b[0m     pipeline, param_grid_learning_rate, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_root_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, groups\u001b[39m=\u001b[39mbins\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bins' is not defined"
     ]
    }
   ],
   "source": [
    "# First, tune the learning rate\n",
    "learning_rates = np.linspace(0.01, 0.35, 70)\n",
    "param_grid_learning_rate = {\n",
    "    'xgb__learning_rate': learning_rates\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    pipeline, param_grid_learning_rate, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1, groups=bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, tune the learning rate\n",
    "learning_rates = np.linspace(0.01, 0.6, 120)\n",
    "param_grid_learning_rate = {\n",
    "    'xgb__learning_rate': learning_rates\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    pipeline, param_grid_learning_rate, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "best_learning_rate = grid_search_lr.best_params_['xgb__learning_rate']\n",
    "print(f\"Best learning rate: {best_learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree-specific parameters\n",
    "param_grid_tree = {\n",
    "    'xgb__min_child_weight': range(1, 10, 1),\n",
    "    'xgb__max_depth': range(1, 10, 1),\n",
    "    'xgb__gamma': np.linspace(0, 1, 11),\n",
    "    'xgb__n_estimators': [100, 200, 300, 400, 500]  # adjust the number of trees\n",
    "}\n",
    "\n",
    "# Use the best learning rate found in the previous search\n",
    "pipeline.set_params(xgb__learning_rate=best_learning_rate)\n",
    "\n",
    "# Perform GridSearchCV for tree-specific parameters\n",
    "grid_search_tree = GridSearchCV(\n",
    "    pipeline, param_grid_tree, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Get the best tree-specific parameters\n",
    "best_min_child_weight = grid_search_tree.best_params_['xgb__min_child_weight']\n",
    "best_max_depth = grid_search_tree.best_params_['xgb__max_depth']\n",
    "best_gamma = grid_search_tree.best_params_['xgb__gamma']\n",
    "best_n_estimators = grid_search_tree.best_params_['xgb__n_estimators']\n",
    "\n",
    "print(f\"Best min_child_weight: {best_min_child_weight}\")\n",
    "print(f\"Best max_depth: {best_max_depth}\")\n",
    "print(f\"Best gamma: {best_gamma}\")\n",
    "print(f\"Best n_estimators: {best_n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic parameters\n",
    "param_grid_stochastic = {\n",
    "    'xgb__subsample': np.linspace(0.5, 1, 6),\n",
    "    'xgb__colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "}\n",
    "\n",
    "# Use the best learning rate and tree-specific parameters found in the previous searches\n",
    "pipeline.set_params(\n",
    "    xgb__learning_rate=best_learning_rate,\n",
    "    xgb__min_child_weight=best_min_child_weight,\n",
    "    xgb__max_depth=best_max_depth,\n",
    "    xgb__gamma=best_gamma,\n",
    "    xgb__n_estimators=best_n_estimators\n",
    ")\n",
    "\n",
    "# Perform GridSearchCV for stochastic parameters\n",
    "grid_search_stochastic = GridSearchCV(\n",
    "    pipeline, param_grid_stochastic, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "grid_search_stochastic.fit(X_train, y_train)\n",
    "\n",
    "# Get the best stochastic parameters\n",
    "best_subsample = grid_search_stochastic.best_params_['xgb__subsample']\n",
    "best_colsample_bytree = grid_search_stochastic.best_params_['xgb__colsample_bytree']\n",
    "\n",
    "print(f\"Best subsample: {best_subsample}\")\n",
    "print(f\"Best colsample_bytree: {best_colsample_bytree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters on the training set (excluding the holdout set)\n",
    "final_pipeline = pipeline.set_params(\n",
    "    xgb__learning_rate=best_learning_rate,\n",
    "    xgb__min_child_weight=best_min_child_weight,\n",
    "    xgb__max_depth=best_max_depth,\n",
    "    xgb__gamma=best_gamma,\n",
    "    xgb__n_estimators=best_n_estimators,\n",
    "    xgb__subsample=best_subsample,\n",
    "    xgb__colsample_bytree=best_colsample_bytree\n",
    ")\n",
    "final_pipeline.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "# Validate the final model on the holdout set\n",
    "holdout_preds = final_pipeline.predict(X_holdout)\n",
    "holdout_rmse = mean_squared_error(y_holdout, holdout_preds, squared=False)\n",
    "print(f\"Holdout RMSE: {holdout_rmse}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters on the entire training data (including the holdout set)\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_preds = final_pipeline.predict(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the tuned model on the holdout set\n",
    "y_holdout_pred = grid_search.predict(X_holdout)\n",
    "holdout_rmse = np.sqrt(mean_squared_error(y_holdout, y_holdout_pred))\n",
    "print(f\"RMSE on holdout set: {holdout_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions for the test set\n",
    "predictions = grid_search.predict(test1.drop(columns=['Index']))\n",
    "\n",
    "# Create a new DataFrame with the same index as the test DataFrame and the predictions\n",
    "test_preds = pd.DataFrame({'id': test1['Index'], 'DIC': predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test_preds DataFrame to a CSV file named xgboost.csv\n",
    "test_preds.to_csv('xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7aa754d285b0720e56622eb5dc35ed99ad0ab03f4a3a2a394e7caf03705652a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
